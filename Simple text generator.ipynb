{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint, choice\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from pprint import pprint\n",
    "\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 MOST COMMON (NON STOPWORD) WORDS:\n",
      " ===================================\n",
      "[('great', 377),\n",
      " ('person', 222),\n",
      " ('us', 185),\n",
      " ('people', 181),\n",
      " ('trade', 146),\n",
      " ('many', 143),\n",
      " ('country', 139),\n",
      " ('big', 137),\n",
      " ('democrats', 129),\n",
      " ('news', 113)]\n",
      "\n",
      "10 MOST COMMON NGRAMS (WINDOW SIZE = 3):\n",
      " ===================================\n",
      "[('the united states', 51),\n",
      " ('the fake news', 51),\n",
      " ('the white house', 34),\n",
      " ('fake news media', 31),\n",
      " ('will be a', 28),\n",
      " ('loves our military', 28),\n",
      " ('all of the', 26),\n",
      " ('has my full', 26),\n",
      " ('strong on crime', 26),\n",
      " ('there was no', 25)]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./trump_corpus.txt\", \"r\") as f:\n",
    "    text = f.read().split(\"\\n\")\n",
    "\n",
    "def word_freq(text_list, remove_stopwords = False):\n",
    "    cnt = Counter()\n",
    "    for text in text_list:\n",
    "        for word in text.split():\n",
    "            word = re.sub(\"[^\\w\\d]\", \"\", word)\n",
    "            word = word.lower()\n",
    "            if word:\n",
    "                if (remove_stopwords and word not in stop_words) or (not remove_stopwords):\n",
    "                    cnt[word] += 1      \n",
    "    return cnt\n",
    "\n",
    "def ngram(text_list, window = 3):\n",
    "    ng = defaultdict(lambda : defaultdict(int))\n",
    "    for text in text_list:\n",
    "        text_words = [re.sub(\"[^\\w\\d]\", \"\", word).lower() for word in text.split()]\n",
    "        if len(text_words) < window:\n",
    "            continue\n",
    "        for i in range(window, len(text_words)):\n",
    "            ng[' '.join(text_words[i-3: i])][text_words[i]] += 1\n",
    "    return ng\n",
    "\n",
    "cnt = word_freq(text, remove_stopwords = True)\n",
    "print('\\n10 MOST COMMON (NON STOPWORD) WORDS:\\n', '='*35)\n",
    "pprint(cnt.most_common(10))\n",
    "\n",
    "ngram_common = Counter()\n",
    "ng = ngram(text)\n",
    "for k, v in ng.items():\n",
    "    n = 0\n",
    "    for v_ in v.values():\n",
    "        n += v_\n",
    "    ngram_common[k] += n\n",
    "\n",
    "print('\\n10 MOST COMMON NGRAMS (WINDOW SIZE = 3):\\n', '='*35)\n",
    "pprint(ngram_common.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SIMPLE TRUMP TEXT GENERATOR USING N GRAM\n",
      "\n",
      "TRUMP: and incredible help in getting our massive tax cut bill everyone is talking really nice to see. parkland we are determined to turn our grief into action full meeting. are starting to find out that it was indeed the\n",
      "\n",
      "TRUMP: only he and bob mueller the leader of the 13 angry democrats and people that worked for obama for 8 years stop they have found no collussion with russia no obstruction but they\n",
      "\n",
      "TRUMP: with meddling in our election where is the dnc server and why didnt the 13 angry democrats plus people who worked 8 years for obama working on the rigged russia witch hunt will\n",
      "\n",
      "TRUMP: believe that with all of the wellwishers. author uses every trick in the book to demean and belittle i wish the people could see the real facts  and our country is doing great best financial\n",
      "\n",
      "TRUMP: the second time with physical assault he doesnt know me but he would go down fast and hard crying all the way for ted in the upcoming primary  he will never let\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def simple_text_generator(ngram, window = 3, length=10):\n",
    "    word_list = choice(list(ngram.keys())).split()\n",
    "    for i in range(30):\n",
    "        word_dict = ngram[' '.join(word_list[-window:])]\n",
    "        if not word_dict:\n",
    "            # this is necessary for non-contigous text\n",
    "            word_list[-1] = word_list[-1] + \".\"\n",
    "            word_list += choice(list(ngram.keys())).split()\n",
    "        sample = randint(1, sum(ngram[' '.join(word_list[-window:])].values()))\n",
    "        for word, count in ngram[' '.join(word_list[-window:])].items():\n",
    "            sample -= count\n",
    "            if sample <= 0: word_list.append(word); break\n",
    "    return ' '.join(word_list)\n",
    "\n",
    "print('\\nSIMPLE TRUMP TEXT GENERATOR USING N GRAM\\n')\n",
    "for _ in range(5):\n",
    "    print(f'TRUMP: {simple_text_generator(ng)}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
